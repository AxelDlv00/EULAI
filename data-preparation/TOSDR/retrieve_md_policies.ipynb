{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019189c9",
   "metadata": {},
   "source": [
    "# Retrieve ToS;DR Markdown Content\n",
    "\n",
    "*This notebook scrapes privacy policy documents whose links where extracted from ToS;DR services and converts them to markdown format using Playwright and browser automation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b316b8",
   "metadata": {},
   "source": [
    "## 1. Load Libraries\n",
    "\n",
    "*Import required packages for async web scraping with Playwright, JSON handling, and progress visualization.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e65ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.progress import (\n",
    "    Progress, SpinnerColumn, BarColumn, TextColumn, \n",
    "    TimeRemainingColumn, MofNCompleteColumn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e842c",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "*Define file paths for input service data, markdown output, content extraction script, and concurrency settings for parallel processing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e945e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('../..')\n",
    "DATA_DIR = ROOT / \"data-generated\" / \"TOSDR\"\n",
    "DATA_FILE = DATA_DIR / \"tosdr_data.jsonl\"\n",
    "MARKDOWN_OUTPUT = DATA_DIR / \"policies_md.jsonl\"\n",
    "EXTENSION_FILE = ROOT / \"chrome-extension\" / \"content.js\"\n",
    "\n",
    "CONCURRENCY_LIMIT = 20\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30010c79",
   "metadata": {},
   "source": [
    "## 3. Scraping Functions\n",
    "\n",
    "*Async functions to process documents in parallel using Playwright browser automation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7174d4",
   "metadata": {},
   "source": [
    "### 3.1 Document Processing Worker\n",
    "\n",
    "*Processes a single document by loading the page, executing JavaScript extraction logic, and saving the markdown result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_document(context, document_task, extraction_script, semaphore, progress, progress_task, output_file):    \n",
    "    async with semaphore:\n",
    "        url = document_task['url']\n",
    "        page = await context.new_page()\n",
    "        \n",
    "        try:\n",
    "            await page.goto(url, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "            await asyncio.sleep(random.uniform(1, 3)) \n",
    "\n",
    "            result = await page.evaluate(extraction_script)\n",
    "\n",
    "            if result and result.get('text'):\n",
    "                output_data = {\n",
    "                    **document_task,\n",
    "                    \"markdown\": result['text'],\n",
    "                    \"status\": \"success\"\n",
    "                }\n",
    "                output_file.write(json.dumps(output_data, ensure_ascii=False) + \"\\n\")\n",
    "                output_file.flush()\n",
    "            else:\n",
    "                progress.console.print(f\"[yellow]⚠ Empty: {document_task['service_name']} ({url})[/yellow]\")\n",
    "\n",
    "        except Exception as e:\n",
    "            error_data = {**document_task, \"status\": \"error\", \"error\": str(e)}\n",
    "            output_file.write(json.dumps(error_data, ensure_ascii=False) + \"\\n\")\n",
    "            output_file.flush()\n",
    "        finally:\n",
    "            await page.close()\n",
    "            progress.update(progress_task, advance=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866a40e",
   "metadata": {},
   "source": [
    "### 3.2 Main Scraping Pipeline\n",
    "\n",
    "*Orchestrates the full scraping process: loading tasks, launching browser, and coordinating parallel document processing with progress tracking.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main_scraper():\n",
    "    if not DATA_FILE.exists():\n",
    "        console.print(f\"[red]File missing: {DATA_FILE}[/red]\")\n",
    "        return\n",
    "\n",
    "    extraction_script = EXTENSION_FILE.read_text(encoding='utf-8')\n",
    "\n",
    "    processed_urls = set()\n",
    "    if MARKDOWN_OUTPUT.exists():\n",
    "        with open(MARKDOWN_OUTPUT, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    processed_urls.add(data['url'])\n",
    "                except: continue\n",
    "\n",
    "    all_services = [json.loads(line) for line in DATA_FILE.read_text(encoding='utf-8').splitlines()]\n",
    "    pending_tasks = []\n",
    "    for service in all_services:\n",
    "        for doc in service.get('documents', []):\n",
    "            if doc['url'] not in processed_urls:\n",
    "                pending_tasks.append({\n",
    "                    \"service_id\": service['service_id'],\n",
    "                    \"service_name\": service['name'],\n",
    "                    \"doc_name\": doc['name'],\n",
    "                    \"url\": doc['url']\n",
    "                })\n",
    "\n",
    "    if not pending_tasks:\n",
    "        console.print(\"[bold green]✔ All markdowns are already extracted![/bold green]\")\n",
    "        return\n",
    "\n",
    "    console.print(f\"[bold blue]Starting parallel scraping ({CONCURRENCY_LIMIT} workers)...[/bold blue]\")\n",
    "\n",
    "    async with async_playwright() as playwright:\n",
    "        browser = await playwright.chromium.launch(headless=True)\n",
    "        browser_context = await browser.new_context(\n",
    "            viewport={'width': 1280, 'height': 800},\n",
    "            locale=\"en-US\",\n",
    "            extra_http_headers={\n",
    "                \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "            },\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "\n",
    "        semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)\n",
    "        \n",
    "        with Progress(\n",
    "            SpinnerColumn(),\n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            BarColumn(),\n",
    "            MofNCompleteColumn(),\n",
    "            TimeRemainingColumn(),\n",
    "            console=console\n",
    "        ) as progress:\n",
    "            \n",
    "            scraping_task = progress.add_task(\"[cyan]Extracting...\", total=len(pending_tasks))\n",
    "            \n",
    "            with open(MARKDOWN_OUTPUT, \"a\", encoding=\"utf-8\") as output_file:\n",
    "                async_tasks = [\n",
    "                    process_document(browser_context, task, extraction_script, semaphore, progress, scraping_task, output_file) \n",
    "                    for task in pending_tasks\n",
    "                ]\n",
    "                await asyncio.gather(*async_tasks)\n",
    "\n",
    "        await browser.close()\n",
    "        console.print(f\"[bold green]✔ Completed! File: {MARKDOWN_OUTPUT}[/bold green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fbe36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await main_scraper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_MINES",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
